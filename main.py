import os
import logging
import asyncio
import google.generativeai as genai
from telegram import Update
from telegram.constants import ChatAction, ChatType
from telegram.ext import (
    ApplicationBuilder,
    ContextTypes,
    CommandHandler,
    MessageHandler,
    filters
)
from keep_alive import keep_alive

# ==========================================
# âš™ï¸ ×”×’×“×¨×•×ª
# ==========================================
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# ×œ×•×’×™×
logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# ==========================================
# ğŸ§  ×”×’×“×¨×ª ×’×•×’×œ + ×‘×—×™×¨×ª ××•×“×œ ××•×˜×•××˜×™×ª
# ==========================================
if not GEMINI_API_KEY:
    print("âŒ ×©×’×™××”: ×—×¡×¨ ××¤×ª×— GEMINI_API_KEY")
    model = None
else:
    genai.configure(api_key=GEMINI_API_KEY)
    
    print("ğŸ” ×¡×•×¨×§ ××•×“×œ×™× ×–××™× ×™× ×‘×—×©×‘×•×Ÿ ×©×œ×š...")
    target_model = "gemini-1.5-flash" # ×‘×¨×™×¨×ª ××—×“×œ
    
    try:
        # ××‘×§×© ××’×•×’×œ ××ª ×”×¨×©×™××” ×”×××™×ª×™×ª ×©×œ ×”××•×“×œ×™× ×”×¤×ª×•×—×™× ×œ××¤×ª×— ×”×–×”
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)
        
        print(f"ğŸ“‹ ×”××•×“×œ×™× ×©×œ×š: {available_models}")

        # ××œ×’×•×¨×™×ª× ×—×›× ×œ×‘×—×™×¨×ª ×”××•×“×œ ×”×›×™ ×˜×•×‘ ×©×§×™×™× ××¦×œ×š
        # ×¢×“×™×¤×•×ª 1: Flash (××”×™×¨)
        # ×¢×“×™×¤×•×ª 2: Pro (×—×–×§)
        # ×¢×“×™×¤×•×ª 3: ××” ×©×™×©
        
        found = False
        # ××—×¤×© ×’×¨×¡××•×ª ×©×œ ×¤×œ××©
        for m in available_models:
            if "flash" in m and "1.5" in m:
                target_model = m
                found = True
                break
        
        if not found:
            # ×× ××™×Ÿ ×¤×œ××©, ××—×¤×© ×¤×¨×•
            for m in available_models:
                if "pro" in m and "1.5" in m:
                    target_model = m
                    found = True
                    break
        
        if not found and available_models:
             # ×× ×œ× ××¦×× ×• ××ª ×”××•×¢×“×¤×™×, ×œ×•×§×—×™× ××ª ×”×¨××©×•×Ÿ ×‘×¨×©×™××” ×•×–×”×•
             target_model = available_models[0]

    except Exception as e:
        print(f"âš ï¸ ×©×’×™××” ×‘×¡×¨×™×§×” (× ×©×ª××© ×‘×‘×¨×™×¨×ª ××—×“×œ): {e}")

    # ×× ×§×” ××ª ×”×©× (×œ×¤×¢××™× ××’×™×¢ ×¢× models/ ×‘×”×ª×—×œ×”)
    if target_model.startswith("models/"):
        target_model = target_model.replace("models/", "")
        
    print(f"âœ… × ×‘×—×¨ ×”××•×“×œ: {target_model}")
    model = genai.GenerativeModel(target_model)

SYSTEM_PROMPT = (
    "××ª Lina, ×¡×•×›× ×ª × ×“×œ\"×Ÿ ××§×¦×•×¢×™×ª ×‘× ×ª× ×™×”. "
    "×¢× ×™ ×‘×¢×‘×¨×™×ª, ×‘×¦×•×¨×” ×§×¦×¨×” (×¢×“ 2 ××©×¤×˜×™×) ×•××–××™× ×”. "
    "×”××˜×¨×”: ×œ×¢×–×•×¨ ×œ×œ×§×•×— ××• ×œ×§×‘×œ ×˜×œ×¤×•×Ÿ."
)

# ==========================================
# ğŸ§  ×¤×•× ×§×¦×™×” ×œ×©×œ×™×—×” ×œ×’×•×’×œ
# ==========================================
def ask_gemini(text: str) -> str:
    if not model:
        return "×ª×§×œ×ª ×”×’×“×¨×•×ª ×‘××¤×ª×— ×’×•×’×œ."

    try:
        prompt = f"{SYSTEM_PROMPT}\nUser: {text}\nLina:"
        # timeout ××•× ×¢ ×ª×§×™×¢×•×ª
        response = model.generate_content(prompt, request_options={'timeout': 10})
        return response.text.strip()
    except Exception as e:
        logger.error(f"Gemini Error: {e}")
        # ×‘××§×¨×” ×©×œ ×©×’×™××”, ××—×–×™×¨ ×”×•×“×¢×” ×‘×¨×•×¨×”
        return f"×©×’×™××” ×˜×›× ×™×ª: {str(e)[:50]}..." 

# ==========================================
# ğŸ“© ×˜×™×¤×•×œ ×‘×”×•×“×¢×•×ª
# ==========================================
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text: return
    
    # ×× ×™×¢×ª ×œ×•×¤×™× ××¢×¨×•×¦×™×
    if update.effective_user.id == 777000: return

    text = update.message.text
    chat_type = update.effective_chat.type
    bot_username = context.bot.username

    # --- ×¡×™× ×•×Ÿ ×§×‘×•×¦×•×ª ×—×›× ---
    if chat_type in [ChatType.GROUP, ChatType.SUPERGROUP]:
        # ×¢×•× ×™× ×¨×§ ×× ×ª×™×™×’×• ××•×ª× ×• ××• ×”×’×™×‘×• ×œ× ×•
        is_mentioned = f"@{bot_username}" in text
        is_reply = (update.message.reply_to_message and 
                    update.message.reply_to_message.from_user.id == context.bot.id)
        
        if not (is_mentioned or is_reply):
            return 

        text = text.replace(f"@{bot_username}", "").strip()

    # ×—×™×•×•×™ ×”×§×œ×“×” (×¨×§ ×‘×¤×¨×˜×™)
    if chat_type == 'private':
        await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    # ×©×œ×™×—×” ×œ×’×•×’×œ ×‘×¨×§×¢
    loop = asyncio.get_running_loop()
    try:
        answer = await loop.run_in_executor(None, ask_gemini, text)
        
        if chat_type == 'private':
            await update.message.reply_text(answer)
        else:
            await update.message.reply_text(answer, quote=True)
            
    except Exception as e:
        print(f"Telegram Error: {e}")

# ==========================================
# ğŸš€ ×”×ª×—×œ×”
# ==========================================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("×”×™×™! ×× ×™ ×œ×™× ×” ğŸ \n××™×š ×× ×™ ×™×›×•×œ×” ×œ×¢×–×•×¨?")

if __name__ == "__main__":
    keep_alive()

    if not TELEGRAM_BOT_TOKEN:
        print("âŒ ×—×¡×¨ ×˜×•×§×Ÿ")
    else:
        app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
        app.add_handler(CommandHandler("start", start))
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

        print("ğŸ¤– ×”×‘×•×˜ ×¨×¥! (××¦×‘ ×–×™×”×•×™ ××•×“×œ ××•×˜×•××˜×™)")
        app.run_polling()
